# -*- coding: utf-8 -*-
"""CNN project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sv0jI8jJx9jnV98jSj9DzxTzn2RgRY4V
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Создаем последовательную модель
model = Sequential()

# Добавляем входной сверточный слой
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))

# Добавляем max pooling слой
model.add(MaxPooling2D((2, 2)))

# Преобразуем результат в векторы
model.add(Flatten())

# Добавляем плотный слой с 64 нейронами
model.add(Dense(64, activation='relu'))

# Добавляем выходной слой с 1 нейроном для бинарной классификации
model.add(Dense(1, activation='sigmoid'))

# Компилируем модель с оптимизатором SGD
opt = SGD(learning_rate=0.002, momentum=0.8)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

# Задаем пути к данным
train_data_dir = '/content/drive/MyDrive/Project#1 Nadira/dino-dragon.zip (Unzipped Files)/test'
test_data_dir = '/content/drive/MyDrive/Project#1 Nadira/dino-dragon.zip (Unzipped Files)/train'

# Создаем генераторы данных для обучения и тестирования
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Загружаем и подготавливаем данные с помощью генераторов
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary'
)

# Создаем генератор данных для тестовых данных
test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary'
)

# Обучаем модель
history = model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator
)

# Оцениваем модель
loss, accuracy = model.evaluate(test_generator)
print(f'Потери на тесте: {loss}, Точность на тесте: {accuracy}')

"""#**Ответы** на вопросы

**Вопрос 1**
Так как перед нами стоит задача бинарной классификации, какую функцию потерь лучше всего применить в нашем случае?
●	бинарная кросс-энтропия (binary crossentropy)

***Вопрос 2 ***
Определите общее количество параметров в модели. Для этого примените метод summary.
●	11215873
"""

model.summary()

"""**Вопрос 3**
Какова медиана точности обучения по всем эпохам?
вариант -0,60 ближе
мой ответ - 0.7081218361854553
"""

import numpy as np

# Получаем значения точности обучения для всех эпох
train_accuracy = history.history['accuracy']

# Вычисляем медиану точности обучения
median_train_accuracy = np.median(train_accuracy)

print("Медиана точности обучения по всем эпохам:", median_train_accuracy)

"""**Вопрос 4**
 Каково стандартное отклонение потерь в процессе обучения по всем эпохам? - варианты не подходят

"""

# Получаем значения потерь обучения для всех эпох
train_loss = history.history['loss']

# Вычисляем стандартное отклонение потерь обучения
std_train_loss = np.std(train_loss)

print("Стандартное отклонение потерь в процессе обучения по всем эпохам:", std_train_loss)
# Оцениваем модель
loss, accuracy = model.evaluate(test_generator)
print(f'Потери на тесте: {loss}, Точность на тесте: {accuracy}')

"""**Вопрос 5**

Обучите модель еще на 10 эпох с использованием указанного выше кода. Не создавайте модель с нуля; продолжите обучение существующей.

Каково среднее значение потерь на тестовом наборе данных по всем эпохам после аугментации?

вариант подходящий 0,77
мой вариант 0,68
"""

#
# Продолжаем обучение модели еще на 10 эпох
history_additional = model.fit(
    train_generator,
    epochs=10,
    validation_data=test_generator
)

# Получаем потери на тестовом наборе данных после аугментации
test_losses = history_additional.history['val_loss']

# Вычисляем среднее значение потерь
mean_test_loss = sum(test_losses) / len(test_losses)

print("Среднее значение потерь на тестовом наборе данных после аугментации:", mean_test_loss)

"""**Вопрос 6**

Каково среднее значение точности на тестовом наборе данных за последние 5 эпох (с 6 по 10) после аугментации?

вариант 0.54 ближе
мой вариант 0.57
"""

# Получаем точность на тестовом наборе данных после аугментации
test_accuracies = history_additional.history['val_accuracy']

# Выбираем точности за последние 5 эпох (индексы с 5 по 9 включительно)
last_5_epoch_test_accuracies = test_accuracies[5:]

# Вычисляем среднее значение точности за последние 5 эпох
mean_test_accuracy_last_5_epochs = sum(last_5_epoch_test_accuracies) / len(last_5_epoch_test_accuracies)

print("Среднее значение точности на тестовом наборе данных за последние 5 эпох после аугментации:", mean_test_accuracy_last_5_epochs)